# -*- coding: utf-8 -*-
"""Untitled43.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C-yZ05KIOr3WghXLEd0Pe_FDfVP7yLQK
"""

import os #paths to file
import numpy as np # linear algebra
import pandas as pd # data processing
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression

# read in csv file as a DataFrame
tr_df = pd.read_csv('C:\Users\Alaa\Desktop\gomy\train.csv')
# explore the first 5 rows
tr_df.head()

# read in csv file as a DataFrame
te_df = pd.read_csv('C:\Users\Alaa\Desktop\gomy\test.csv')
# explore the first 5 rows
te_df.head()

#column information
tr_df.info(verbose=True)

#summary statistics
tr_df.describe()

#the Id column is not needed, let's drop it for both test and train datasets
tr_df.drop('Loan_ID',axis=1,inplace=True)
te_df.drop('Loan_ID',axis=1,inplace=True)
#checking the new shapes
print(f"training set (row, col): {tr_df.shape}\n\ntesting set (row, col): {te_df.shape}")

#missing values in decsending order
tr_df.isnull().sum().sort_values(ascending=False)

#filling the missing data
print("Before filling missing values\n\n","#"*50,"\n")
null_cols = ['Credit_History', 'Self_Employed', 'LoanAmount','Dependents', 'Loan_Amount_Term', 'Gender', 'Married']


for col in null_cols:
    print(f"{col}:\n{tr_df[col].value_counts()}\n","-"*50)
    tr_df[col] = tr_df[col].fillna(
    tr_df[col].dropna().mode().values[0] )


tr_df.isnull().sum().sort_values(ascending=False)
print("After filling missing values\n\n","#"*50,"\n")
for col in null_cols:
    print(f"\n{col}:\n{tr_df[col].value_counts()}\n","-"*50)

#list of all the columns.columns
#Cols = tr_df.tolist()
#list of all the numeric columns
num = tr_df.select_dtypes('number').columns.to_list()
#list of all the categoric columns
cat = tr_df.select_dtypes('object').columns.to_list()

#numeric df
loan_num =  tr_df[num]
#categoric df
loan_cat = tr_df[cat]

tr_df = tr_df.dropna()
te_df = te_df.dropna()
tr_df['Dependents'] = tr_df['Dependents'].replace('3+', 3).astype(float)
te_df['Dependents'] = te_df['Dependents'].replace('3+', 3).astype(float)

tr_df["Gender"].unique()

tr_df["Married"].unique()

tr_df["Education"].unique()

tr_df["Property_Area"].unique()

tr_df["Loan_Status"].unique()

from sklearn.preprocessing import LabelEncoder

# Using LabelEncoder to encode categorical variables
le = LabelEncoder()

# List of categorical columns to encode
categorical_cols = tr_df.select_dtypes(include=['object']).columns.to_list()

# Applying LabelEncoder to each categorical column in both train and test datasets
for col in categorical_cols:
    tr_df[col] = le.fit_transform(tr_df[col])

tr_df["Gender"].unique()

tr_df["Married"].unique()

tr_df["Education"].unique()

tr_df["Property_Area"].unique()

tr_df["Loan_Status"].unique()



y = tr_df['Loan_Status']
X = tr_df.drop('Loan_Status', axis = 1)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)

LR = LogisticRegression()
LR.fit(X_train, y_train)

y_predict = LR.predict(X_test)

#  prediction Summary by species
print(classification_report(y_test, y_predict))

# Accuracy score
LR_SC = accuracy_score(y_predict,y_test)
print('accuracy is',accuracy_score(y_predict,y_test))

import pickle
with open('logistic_regression_model.pkl', 'wb') as file:
    pickle.dump(LR, file)



